# Project Plan

### Design Goal
Create a toolkit to ease the development of context inference apps, achieving the following high-level goals:
* Assist the **collection of sensor data and ground truth labels** from user
* Automatically **compose the inference pipeline** from collected dataset, including the training and tuning of machine learning models
* Support **manual configuration** of the inference pipeline
* **Runtime optimization** of inference executions by partitioning the task across multiple devices and heterogeneous processors

### System Component
##### Data Collector
This is an Android app for helping developers collect a set of data from users, possibly including the ground truth label. The workflow is described as follows:

1. App developers specify the set of sensors to be considered, including:
  * Device: a smartphone, a smartwatch, or other external devices.
  * Sensor on each device:, e.g., accelerometer, gyroscope, or a combination of multiple sensors.
  * Sensor configuration: e.g., frequency (limited by the device's sensing capabilities).
  * Ground truth configuration: if ground truth needs to be collected, what is the format of the ground truth label (e.g., nominal, real number, arbitrary string, etc.), and how frequently should the app query the user for labels.
  * Amount of data required: e.g., in terms of size, duration, number of certain ground truth labels, etc.
   
   The above information could be specified using a JSON file and then as an input to the Data Collector app. If time permits I will also develop the UI for configuration. 

2. Target users install the Data Collector app, which collects data based on the developer's configuration. The app runs continuously on the target user's phone and periodically query ground truth labels (if necessary) until the desired amount of data has been collected.

3. The Data Collector app outputs the data, either to a file or to a cloud data storage service.

##### Inference Composer
This is a set of Python or Java APIs for assisting the composition of inference pipelines. 

**App developers** can compose an inference pipeline in one of the following two modes:
- **Manual mode**: App developers use the API to specify the sensors to be considered, feature functions, and a classification model. By supplying a dataset obtained from the Data Collector app, an inference pipeline can be trained and saved.

- **Automatic mode**: App developers use the API to pick a specific inference (or a categories of inferences) and specify certain criteria, for example, a thresholding inference accuracy. The composer automatically selects the right classifier and feature algorithms (if required) to meet the criteria, and returns the trained inference pipeline. 

   To support the automatic mode, there will be **inference developers** (machine learning experts) adding feature calculation and classifier building blocks into a library in the composer app. We will provide base classes for implementing new building blocks but will ship default models with the app as well. 

The composer can save a trained inference pipeline into a file using certain serialization techniques, e.g. Python's `pickle` library or Java's `Serializable` class.

##### Runtime Optimizer
This is an Android app for actualizing an inference pipeline generated by the Inference Composer and optimizing its execution across devices.

The runtime loads a saved piepline from a file or from the network, and instantiate the pipeline using pre-defined Java classes.

The runtime considers several target to run different stages of the inference pipeline, as demonstrated as follows. For each mobile device, the runtime can consider different heterogeneous processors:

```
Cloud
^
|
| WiFi
|
v
Smartphone (CPU, DSP, GPU)
^
|
| Bluetooth LE / WiFi
|
v
Wearable (CPU, DSP, GPU)
```

The runtime app comes with a few default optimizer, such as minimizing network transfer or CPU usage. It also provides APIs for developers to add other customizer profiler and optimizer. 

### Timeline
Total time: 8 weeks

| Task | Time | Note |
| ---  |:---: | ---  |
| Designing and implementing the Data Collector App | 1.5 week | Re-use part of the WorkoutRecorder app |
| Creating custom APIs for manually composing inferences | 1 week | Re-use the primitive APIs in the DSP work |
| Adding existing algorithms (e.g. features, models) for the automatically inference composition | 1 week | Wrappers for Tensorflow, scikit-learn, etc. |
| Designing and implementing the automatic inference composition | 1.5 weeks | |
| Creating the runtime optimization app | 2 weeks | |

### Issue
- Can we adopt the data format proposed by the MD2K mCerebum project?
