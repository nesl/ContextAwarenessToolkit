## Inference Composer
Inference Composer is a Python program that provides high-level APIs for training machine learning models from data generated by Data Collector. It eases the inference model training by offering an automatic training mode, where a set of default classifiers are trained on a dataset and the model with the best performance is returned to the developer.
Moveover, Inference Composer closes the gap between popular machine learning frameworks (e.g. scikit-learn and Tensorflow [ten]) and mobile operating systems such as Android. 
Inference Composer can export an inference pipeline trained by these frameworks (in Python) to a JSON file that can be parsed, initialized, and executed on Android using the Inference Executor app described next.
In doing so it saves trained classification models in the form of [Predictive Model Markup Language (PMML)](https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language) which can then be loaded by the Inference Executor.

### Usage
With Inference Composer, **machine learning experts** (i.e. inference developers) create inference modules by implementing a `ModuleBase` interface. Each inference module must implement two methods:
- `process()` takes a data vector, performs inference computation, and returns a data vector.
- `export()` saves the module itself in JSON format, including transforming scikit classifiers to PMML using [sklearn2pmml](https://github.com/jpmml/sklearn2pmml).

**App developers** then feed sensor data into Inference Composer. Inference Composer offer two modes of composing inferences:
- Manual mode: App developers use the API to specify the sensors to be considered, pre-processing functions, feature functions, and classification models (given that these modules exist in the current module library). By supplying a dataset obtained from Data Collector, an inference pipeline can be trained based on the specifications and saved to a JSON file.
- Automatic mode: App developers use the API to pick a specific inference and specify cer- tain criteria, for example, a thresholding inference accuracy or simply requesting a classifier with the best accuracy. Based on the dataset, Inference Composer automatically selects the right classifier and feature algorithms (if required) from the current module library to meet the criteria, and returns the trained inference pipeline.

After an inference pipeline is created, it can be exported to a JSON file by invoking the `export()` method of each of its member inference module. 

### Implementation
Inference Composer is implemented in Python and provides wrapper functions for both scikit-learn and Tensorflow, enabling it to leverage both traditional machine learning models and deep neural networks. It provides a set of default inference modules but also allows inference developers to add new modules using the ModuleBase interface. In order to export scikit classifiers into PMML, Inference Composer uses the open-source [sklearn2pmml].

### API Example
```
# Pre-processing
pre_processor = Preprocess.Preprocess(
  _window_size=1,
  _data_columns=data_columns,
  _operators=[Preprocess.MOVING_AVG_SMOOTH]
processed_data = pre_processor.process(raw_data)

# Feature calculation
feature_calculator = Feature.Feature(
  _window_size=1,
  _data_columns=data_columns,
  _features=features
)
feature_vector = feature_calculator.process(processed_data)

# Train default classifiers and show performance
classifiers = Classifier.Classifier(
   _feature_mapper=feature_calculator.get_mapper(),
    _model_path=MODEL_PATH,
    _cross_validation=True,
    _cv_fold=10
)
classifiers.add_default_classifiers()
classifiers.process(feature_vector)

# Export the trained pipeline to JSON,
# including automatically transforming model to PMML
export_inference([pre_processor, feature_calculator, classifiers])
```
Developers configure pre-processing, feature calculation, and classifiers using existing inference modules. They can export the entire inference as a JSON file after specifying each modules.